{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, df_inf, tknzr):\n",
    "    ds_inf = CNNDailyMailDataset(df_inf, tknzr)\n",
    "    dl_inf = DataLoader(ds_inf, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    summary_list = []\n",
    "    for (input_ids, attention_mask, _, _) in tqdm(dl_inf):\n",
    "        # set data to same device as model\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        # run model\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(input_ids, attention_mask=attention_mask,\n",
    "                               do_sample=True, \n",
    "                               top_k=50, \n",
    "                               top_p=0.95\n",
    "                              )\n",
    "        summaries = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "        summary_list.extend(summaries)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    df_generated = df_inf.copy()\n",
    "    df_generated['generated'] = summary_list\n",
    "    return df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generated = inference(t5_model, df_test[:100], tokenizer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
